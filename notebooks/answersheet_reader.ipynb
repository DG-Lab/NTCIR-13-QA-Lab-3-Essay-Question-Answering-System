{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MecabNode:\n",
    "    def __init__(\n",
    "            self,\n",
    "            surface: str=None,\n",
    "            syntax_type: str=None,\n",
    "            sub_syntax_type: str=None,\n",
    "            semantic_type: str=None,\n",
    "            sub_semantic_type: str=None,\n",
    "            reading: str=None):\n",
    "        self.surface = surface\n",
    "        self.syntax_type = syntax_type\n",
    "        self.sub_syntax_type = sub_syntax_type\n",
    "        self.semantic_type = semantic_type\n",
    "        self.sub_semantic_type = sub_semantic_type\n",
    "        self.reading = reading\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '[{}]({}/{}/{}/{}/{})'.format(self.surface,\n",
    "                                             self.syntax_type, self.sub_syntax_type,\n",
    "                                             self.semantic_type, self.sub_semantic_type,\n",
    "                                             self.reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import MeCab\n",
    "\n",
    "\n",
    "class MecabWrapper:\n",
    "    def __init__(self):\n",
    "        mecab_ipadic_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd/'\n",
    "        assert os.path.exists(mecab_ipadic_path), 'mecab-ipadic-neologd not found. Exitting.'\n",
    "        self.tagger = MeCab.Tagger('-d {}'.format(mecab_ipadic_path))\n",
    "        self.tagger.parse('')\n",
    "\n",
    "    def get_nodes(self, sentence: str) -> List[MecabNode]:\n",
    "        \"\"\"Get a list of `MecabNode`s from the given sentence\n",
    "\n",
    "        Args:\n",
    "            sentence (str): input sentence\n",
    "\n",
    "        Returns:\n",
    "            nodes (list): a list of `MecabNode` objects\n",
    "\n",
    "        :param sentence: str\n",
    "        :return: List[MecabNode]\n",
    "        \"\"\"\n",
    "        node_ptr = self.tagger.parseToNode(sentence)\n",
    "        nodes = []\n",
    "        while node_ptr:\n",
    "            features = node_ptr.feature.split(',')\n",
    "            if 'BOS/EOS' != features[0]:\n",
    "                reading = features[7] if len(features) > 7 else node_ptr.surface\n",
    "                nodes.append(MecabNode(node_ptr.surface,\n",
    "                                       features[0], features[1], features[2], features[3], reading))\n",
    "            node_ptr = node_ptr.next\n",
    "        return nodes\n",
    "\n",
    "    def get_readings(self, sentence: str) -> List[str]:\n",
    "        nodes = self.get_nodes(sentence)\n",
    "        return [node.reading for node in nodes]\n",
    "\n",
    "    def get_words(self, sentence: str) -> List[str]:\n",
    "        nodes = self.get_nodes(sentence)\n",
    "        return [node.surface for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element_texts(parent_element, xpath):\n",
    "    texts = []\n",
    "    for element in parent_element.findall(xpath):\n",
    "        text = ''.join(element.itertext())\n",
    "        if text:\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length_limit(parent_element):\n",
    "    return int(re.findall(r'\\d+', parent_element.find('answer_set/answer/[@length_limit]').get('length_limit'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conditions_list(root):\n",
    "    conditions_list = []\n",
    "    for answer_section in root.iter('answer_section'):\n",
    "        section_id = answer_section.get('id')\n",
    "        grands = get_element_texts(answer_section, 'grand_question_set/grand_question')\n",
    "        instructions = get_element_texts(answer_section, 'instruction/p')\n",
    "        refs = get_element_texts(answer_section, 'reference_set/reference/[@is_directly_referred=\"0\"]')\n",
    "        direction = get_element_texts(answer_section, 'reference_set/reference/[@is_directly_referred=\"1\"]')\n",
    "        keywords = get_element_texts(answer_section, 'keyword_set/keyword')\n",
    "        viewpoints = get_element_texts(answer_section, 'viewpoint_set/viewpoint')\n",
    "        answer_length_limit = get_length_limit(answer_section)\n",
    "        conditions = {\n",
    "            'section_id': section_id,\n",
    "            'grands': grands,\n",
    "            'instructions': instructions,\n",
    "            'refs': refs,\n",
    "            'direction': direction,\n",
    "            'keywords': keywords,\n",
    "            'viewpoints': viewpoints,\n",
    "            'answer_length_limit': answer_length_limit\n",
    "        }\n",
    "        conditions_list.append(conditions)\n",
    "    return conditions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_noun_ja(text):\n",
    "    tokens = []\n",
    "    tagger = MecabWrapper()\n",
    "    nodes = tagger.get_nodes(text)\n",
    "    for node in nodes:\n",
    "        if '名詞' == node.syntax_type:\n",
    "            tokens.append(node.surface)\n",
    "            # if '固有名詞' == node.sub_syntax_type:\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_query_string_list_ja(conditions_list_ja):\n",
    "    def pattern_filter(text):\n",
    "        patterns = [r'\\d+字以内', r'[\\(\\)]', r'下線部\\w', r'図版\\w', r'[ＸＹＺ]']\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "        return text\n",
    "\n",
    "    query_string_list = []\n",
    "    for conditions in conditions_list_ja:\n",
    "        query_string_template = '#combine({})'\n",
    "        phrases = []\n",
    "        keyterms = conditions['keywords']\n",
    "        if keyterms:\n",
    "            for keyterm in keyterms:\n",
    "                phrase = '#1({})'.format(' '.join(list(\n",
    "                    keyterm\n",
    "                )).replace('(', '').replace(')', ''))\n",
    "                phrases.append(phrase)\n",
    "        else:\n",
    "            raw_phrases = []\n",
    "            if conditions['instructions']:\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['instructions'][0]\n",
    "                    ))\n",
    "                instruction_phrase = ' '.join(list(\n",
    "                    pattern_filter(\n",
    "                        conditions['instructions'][0]\n",
    "                    )\n",
    "                ))\n",
    "                phrases.append(instruction_phrase)\n",
    "            if conditions['refs']:\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['refs'][0]\n",
    "                    ))\n",
    "                ref_phrase = ' '.join(list(\n",
    "                    pattern_filter(\n",
    "                        conditions['refs'][0]\n",
    "                    )\n",
    "                ))\n",
    "                phrases.append(ref_phrase)\n",
    "            if conditions['direction']:\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['direction'][0]\n",
    "                    ))\n",
    "                direction_phrase = ' '.join(list(\n",
    "                    pattern_filter(\n",
    "                        conditions['direction'][0]\n",
    "                    )\n",
    "                ))\n",
    "                phrases.append(direction_phrase)\n",
    "            if conditions['viewpoints']:\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['viewpoints'][0]\n",
    "                    ))\n",
    "                viewpoint_phrase = ' '.join(list(\n",
    "                    pattern_filter(\n",
    "                        conditions['viewpoints'][0]\n",
    "                    )\n",
    "                ))\n",
    "                phrases.append(viewpoint_phrase)\n",
    "            new_phrases = []\n",
    "            for raw_phrase in raw_phrases:\n",
    "                nouns = filter_by_noun_ja(raw_phrase)\n",
    "                for noun in nouns:\n",
    "                    term = '#1({})'.format(' '.join(list(\n",
    "                        noun\n",
    "                    )).replace('(', '').replace(')', ''))\n",
    "                    new_phrases.append(term)\n",
    "            phrases.extend(new_phrases)\n",
    "        query_string = query_string_template.format(' '.join(phrases))\n",
    "        query_string_list.append(query_string)\n",
    "    return query_string_list\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    with Popen(['java', 'edu.stanford.nlp.process.PTBTokenizer', '-preserveLines'],\n",
    "               stdin=PIPE, stdout=PIPE, stderr=PIPE) as tokenizer_proc:\n",
    "        out, err = tokenizer_proc.communicate(input=text.encode('UTF-8'))\n",
    "        return out.decode('UTF-8')\n",
    "\n",
    "\n",
    "def tag_pos_en(text):\n",
    "    with Popen([\n",
    "        'java', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '--model',\n",
    "        'edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger'],\n",
    "            stdin=PIPE, stdout=PIPE, stderr=PIPE) as tokenizer_proc:\n",
    "        out, err = tokenizer_proc.communicate(input=text.encode('UTF-8'))\n",
    "        return out.decode('UTF-8')\n",
    "\n",
    "\n",
    "def filter_by_noun_en(text):\n",
    "    return re.findall(r'\\b(\\w+)_NN\\b', tag_pos_en(text))\n",
    "\n",
    "\n",
    "def get_query_string_list_en(conditions_list_en):\n",
    "    def pattern_filter(text):\n",
    "        patterns = [\n",
    "            r'(\\d+ English words or less)',\n",
    "            r'[\\(\\)]',\n",
    "            r'(underlined section \\(\\d+\\))',\n",
    "            r'(Plate \\w)',\n",
    "            r'\\b[XYZ]\\b',\n",
    "            r'[,.?\\'\"\\-`“”’]',\n",
    "            r'(’s)'\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "    query_string_list = []\n",
    "    for conditions in conditions_list_en:\n",
    "        query_string_template = '#combine({})'\n",
    "        phrases = []\n",
    "        keyterms = conditions['keywords']\n",
    "        if keyterms:\n",
    "            for keyterm in keyterms:\n",
    "                phrase = '#1({})'.format(\n",
    "                    pattern_filter(\n",
    "                        keyterm\n",
    "                    )\n",
    "                )\n",
    "                phrases.append(phrase)\n",
    "        else:\n",
    "            raw_phrases = []\n",
    "            if conditions['instructions']:\n",
    "                instruction_phrase = conditions['instructions'][0]\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['instructions'][0]\n",
    "                    ))\n",
    "                phrases.append(\n",
    "                    pattern_filter(\n",
    "                        instruction_phrase\n",
    "                    )\n",
    "                )\n",
    "            if conditions['refs']:\n",
    "                ref_phrase = conditions['refs'][0]\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['refs'][0]\n",
    "                    ))\n",
    "                phrases.append(\n",
    "                    pattern_filter(\n",
    "                        ref_phrase\n",
    "                    )\n",
    "                )\n",
    "            if conditions['direction']:\n",
    "                direction_phrase = conditions['direction'][0]\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['direction'][0]\n",
    "                    ))\n",
    "                phrases.append(\n",
    "                    pattern_filter(\n",
    "                        direction_phrase\n",
    "                    )\n",
    "                )\n",
    "            if conditions['viewpoints']:\n",
    "                viewpoint_phrase = conditions['viewpoints'][0]\n",
    "                raw_phrases.append(\n",
    "                    pattern_filter(\n",
    "                        conditions['viewpoints'][0]\n",
    "                    ))\n",
    "                phrases.append(\n",
    "                    pattern_filter(\n",
    "                        viewpoint_phrase\n",
    "                    )\n",
    "                )\n",
    "            new_phrases = []\n",
    "            for raw_phrase in raw_phrases:\n",
    "                nouns = filter_by_noun_en(raw_phrase)\n",
    "                for noun in nouns:\n",
    "                    term = '#1({})'.format(\n",
    "                        pattern_filter(\n",
    "                            noun\n",
    "                        )\n",
    "                    )\n",
    "                new_phrases.append(term)\n",
    "            phrases.extend(new_phrases)\n",
    "        query_string = query_string_template.format(' '.join(phrases))\n",
    "        query_string_list.append(query_string)\n",
    "    return query_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_ja(query_string_list_ja):\n",
    "    parameter_template = (\n",
    "        '<parameters>\\n'\n",
    "        ' <index>qalab3-essay-phase2/indri/indexes/tokyoshoseki</index>\\n'\n",
    "        ' <index>qalab3-essay-phase2/indri/indexes/yamakawa</index>\\n'\n",
    "        ' <index>qalab3-essay-phase2/indri/indexes/jawiki</index>\\n'\n",
    "        '\\n{}\\n'\n",
    "        '</parameters>\\n'\n",
    "    )\n",
    "    query_element_template = (\n",
    "        '  <query>\\n'\n",
    "        '   <type>indri</type>\\n'\n",
    "        '   <number>{}</number>\\n'\n",
    "        '   <text>\\n'\n",
    "        '    {}\\n'\n",
    "        '   </text>\\n'\n",
    "        '  </query>\\n'\n",
    "    )\n",
    "\n",
    "    query_elements = []\n",
    "    for i, query in enumerate(query_string_list_ja):\n",
    "        query_element = query_element_template.format(i, query)\n",
    "        query_elements.append(query_element)\n",
    "    parameters = parameter_template.format('\\n'.join(query_elements))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_parameters_en(query_string_list_en):\n",
    "    parameter_template = (\n",
    "        '<parameters>\\n'\n",
    "        ' <index>qalab3-essay-phase2/indri/indexes/enwiki</index>\\n'\n",
    "        ' <stemmer><name>krovetz</name></stemmer>\\n'\n",
    "        '\\n{}\\n'\n",
    "        '</parameters>\\n'\n",
    "    )\n",
    "    query_element_template = (\n",
    "        '  <query>\\n'\n",
    "        '   <type>indri</type>\\n'\n",
    "        '   <number>{}</number>\\n'\n",
    "        '   <text>\\n'\n",
    "        '    {}\\n'\n",
    "        '   </text>\\n'\n",
    "        '  </query>\\n'\n",
    "    )\n",
    "\n",
    "    query_elements = []\n",
    "    for i, query in enumerate(query_string_list_en):\n",
    "        query_element = query_element_template.format(i, query)\n",
    "        query_elements.append(query_element)\n",
    "    parameters = parameter_template.format('\\n'.join(query_elements))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_indri_query(parameter_file_path):\n",
    "    with Popen(['IndriRunQuery', parameter_file_path, '-trecFormat=true', '-count=10'],\n",
    "               stdout=PIPE, stderr=PIPE) as indri_proc:\n",
    "        out, err = indri_proc.communicate()\n",
    "        return out.decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pow\n",
    "\n",
    "\n",
    "def parse_result(result):\n",
    "    result_set = {}\n",
    "    result_lines = result.splitlines()\n",
    "    for line in result_lines:\n",
    "        fields = line.split(' ')\n",
    "        serial = fields[0]\n",
    "        doc_id = fields[2]\n",
    "        rank = fields[3]\n",
    "        score = fields[4]\n",
    "        prob = pow(2, float(score))\n",
    "        if serial not in result_set:\n",
    "            result_set[serial] = []\n",
    "        result_set[serial].append({'doc_id': doc_id, 'rank': rank, 'score': score, 'prob': prob})\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def attach_doc_ja(result_set, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    set_size = len(result_set)\n",
    "    for i in range(set_size):\n",
    "        candidates = result_set[str(i)]\n",
    "        for j, candidate in enumerate(candidates):\n",
    "            doc_id = candidate['doc_id']\n",
    "            cursor.execute('SELECT doc FROM ja_docs WHERE doc_no=?', (doc_id,))\n",
    "            all_rows = []\n",
    "            for row in cursor:\n",
    "                all_rows.append(row[0])\n",
    "            result_set[str(i)][j]['doc'] = '\\n'.join(all_rows)\n",
    "    return result_set\n",
    "\n",
    "\n",
    "def attach_doc_en(result_set, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    set_size = len(result_set)\n",
    "    for i in range(set_size):\n",
    "        candidates = result_set[str(i)]\n",
    "        for j, candidate in enumerate(candidates):\n",
    "            doc_id = candidate['doc_id']\n",
    "            cursor.execute('SELECT doc FROM en_docs WHERE doc_no=?', (doc_id,))\n",
    "            for row in cursor:\n",
    "                result_set[str(i)][j]['doc'] = row[0]\n",
    "                break\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attach_sentence(result_set_with_docs, query_string_list):\n",
    "    set_size = len(result_set_with_docs)\n",
    "    for i in range(set_size):\n",
    "        query_string = query_string_list[i]\n",
    "        query_string = query_string.replace('#combine(', '').replace('#1(', '').replace(')', '')\n",
    "        tokens = map(lambda x: '({})'.format(x), query_string.split(' '))\n",
    "        pattern = '|'.join(tokens)\n",
    "        candidates = result_set_with_docs[str(i)]\n",
    "        for j, candidate in enumerate(candidates):\n",
    "            doc = candidate['doc']\n",
    "            doc_lines = doc.splitlines()\n",
    "            sentences = []\n",
    "            sentence_set = set()\n",
    "            for line in doc_lines:\n",
    "                if line.startswith('<DOC') or line.startswith('</DOC') \\\n",
    "                        or line.startswith('<TEXT>') or line.startswith('</TEXT>'):\n",
    "                    continue\n",
    "                sentence = line.replace('<Title>', '').replace('</Title>', '').strip()\n",
    "                if sentence in sentence_set:\n",
    "                    continue\n",
    "                sentence_set.add(sentence)\n",
    "                matches = re.findall(pattern, sentence)\n",
    "                if matches:\n",
    "                    sentences.append({'sentence': sentence, 'match_count': len(matches)})\n",
    "            result_set_with_docs[str(i)][j]['sentences'] = sentences\n",
    "    return result_set_with_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attach_passage(result_set_with_sentences):\n",
    "    set_size = len(result_set_with_sentences)\n",
    "    for i in range(set_size):\n",
    "        candidates = result_set_with_sentences[str(i)]\n",
    "        for j, candidate in enumerate(candidates):\n",
    "            sorted_sentences = sorted(candidate['sentences'], key=lambda x: x['match_count'], reverse=True)\n",
    "            passage = '\\n'.join([s['sentence'] for s in sorted_sentences[:7]])\n",
    "            result_set_with_sentences[str(i)][j]['passage'] = passage\n",
    "    return result_set_with_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extraction_xml(result_set_with_passages, conditions_list):\n",
    "    topic_element_template = (\n",
    "        '<TOPIC ID=\"{}\">\\n'\n",
    "        ' <PASSAGE_SET>\\n'\n",
    "        '{}'\n",
    "        ' </PASSAGE_SET>\\n'\n",
    "        '</TOPIC>\\n'\n",
    "    )\n",
    "    passage_element_template = (\n",
    "        '  <PASSAGE RANK=\"{}\" SOURCE_ID=\"{}\" SOURCE_ID_TYPE=\"QALab3\" SCORE=\"{}\" NORMALIZED_SCORE=\"{}\">\\n'\n",
    "        '   {}\\n'\n",
    "        '  </PASSAGE>\\n'\n",
    "    )\n",
    "\n",
    "    topic_elements = []\n",
    "    set_size = len(result_set_with_passages)\n",
    "    for i in range(set_size):\n",
    "        section_id = conditions_list[i]['section_id']\n",
    "        candidates = result_set_with_passages[str(i)]\n",
    "        passage_elements = []\n",
    "        for candidate in candidates:\n",
    "            rank = candidate['rank']\n",
    "            doc_id = candidate['doc_id']\n",
    "            score = candidate['score']\n",
    "            prob = candidate['prob']\n",
    "            passage = candidate['passage']\n",
    "            passage_element = passage_element_template.format(rank, doc_id, score, prob, passage)\n",
    "            passage_elements.append(passage_element)\n",
    "        passage_set = ''.join(passage_elements)\n",
    "        topic_element = topic_element_template.format(section_id, passage_set)\n",
    "        topic_elements.append(topic_element)\n",
    "    topic_set = ''.join(topic_elements)\n",
    "    extraction_xml = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n{}'.format(topic_set)\n",
    "    return extraction_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ja = et.parse('qalab3-essay-phase2/_references/qalab3-ja-essay-phase2/qalab3-ja-phase2-answersheet-essay.xml')\n",
    "conditions_list_ja = get_conditions_list(tree_ja.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#combine(#1(ア ク テ ィ ウ ム の 海 戦) #1(イ ス ラ ム 教) #1(オ ス マ ン 帝 国) #1(サ ラ デ ィ ン) #1(ナ イ ル 川) #1(ナ セ ル) #1(ナ ポ レ オ ン) #1(ム ハ ン マ ド ・ ア リ ー))',\n '#combine(日 本 は の 連 合 組 織 に 参 加 し ， 後 に 脱 退 し た 。 脱 退 の 経 緯 を で 記 せ 。 連 合 組 織 #1(日 本) #1(連 合) #1(組 織) #1(参 加) #1(，) #1(後) #1(脱 退) #1(脱 退) #1(経 緯) #1(連 合) #1(組 織))',\n '#combine(の 戦 争 の な か に は ， 1 9 4 8 年 ５ 月 に 始 ま っ た 第 一 次 中 東 戦 争 パ レ ス テ ィ ナ 戦 争 が あ る 。 こ の 戦 争 の 結 果 ど の よ う な こ と が 起 こ っ た か ， で 説 明 せ よ 。 一 連 の 戦 争 #1(戦 争) #1(な か) #1(1 9 4 8 年) #1(５ 月) #1(第 一 次 中 東 戦 争) #1(パ レ ス テ ィ ナ) #1(戦 争) #1(戦 争) #1(結 果) #1(よ う) #1(こ と) #1(説 明) #1(一 連) #1(戦 争))',\n '#combine(#1(植 民 地 奴 隷 制 の 廃 止) #1(サ ト ウ キ ビ ・ プ ラ ン テ ー シ ョ ン) #1(ゴ ー ル ド ・ ラ ッ シ ュ) #1(海 禁) #1(ア ヘ ン 戦 争) #1(海 峡 植 民 地) #1(利 権 回 収 運 動) #1(孫 文))',\n '#combine(は ， 1 6 ～ 1 7 世 紀 の 間 に 宗 教 政 策 を 大 き く 変 え た 。 そ の 変 化 を ， 関 係 す る 二 人 の 皇 帝 の 名 を 用 い ， で 説 明 せ よ 。 関 係 す る 二 人 の 皇 帝 の 名 を 用 い #1(1 6) #1(1 7 世 紀) #1(間) #1(宗 教) #1(政 策) #1(変 化) #1(関 係) #1(二 人) #1(皇 帝) #1(名) #1(説 明) #1(関 係) #1(二 人) #1(皇 帝) #1(名) #1(用 い))',\n '#combine(に は ， 異 教 徒 処 遇 の 制 度 が あ っ た 。 a そ の 通 称 を 記 し ， b 特 徴 を ， で 説 明 せ よ 。 #1(異 教 徒) #1(処 遇) #1(制 度) #1(a) #1(通 称) #1(b) #1(特 徴) #1(説 明))',\n '#combine(と に は ， そ れ ぞ れ ジ ャ ー ギ ー ル 制 ， テ ィ マ ー ル 制 と 呼 ば れ る 類 似 の 制 度 が み ら れ た 。 両 者 の 共 通 の 特 徴 を で 記 せ 。 #1(そ れ ぞ れ) #1(ジ ャ ー ギ ー ル) #1(制) #1(テ ィ マ ー ル) #1(制) #1(類 似) #1(制 度) #1(両 者) #1(共 通) #1(特 徴))',\n '#combine(は 1 6 世 紀 の 城 壁 を も っ た 都 市 を 示 し て い る 。 こ の よ う な 突 き 出 た 稜 堡 を も っ た 城 壁 は ， 1 6 世 紀 以 降 さ か ん に つ く ら れ た 。 戦 術 を 一 変 さ せ ， こ う し た 城 壁 を つ く ら せ た 理 由 は な に か 。 で 答 え よ 。 #1(1 6 世 紀) #1(城 壁) #1(都 市) #1(よ う) #1(稜) #1(堡) #1(城 壁) #1(1 6 世 紀) #1(以 降) #1(さ か ん) #1(戦 術) #1(一 変) #1(城 壁) #1(理 由) #1(な に) #1(答 え))',\n '#combine(#1(ウ ェ ス ト フ ァ リ ア 条 約) #1(国 際 連 盟) #1(十 四 カ 条) #1(『 戦 争 と 平 和 の 法 』) #1(総 力 戦) #1(徴 兵 制) #1(ナ シ ョ ナ リ ズ ム) #1(平 和 に 関 す る 布 告))',\n '#combine(イ ン ド 亜 大 陸 へ の イ ス ラ ー ム の 定 着 は 海 陸 両 方 の 経 路 か ら 進 行 し た 。 そ の う ち ， カ イ バ ル 峠 を 通 る ル ー ト に よ る 定 着 過 程 の ， 1 0 世 紀 末 か ら 1 6 世 紀 前 半 に か け て の 展 開 を ， 政 治 的 側 面 と 文 化 的 側 面 の 双 方 に ふ れ な が ら で 説 明 し な さ い 。 政 治 的 側 面 と 文 化 的 側 面 の 双 方 に ふ れ な が ら #1(イ ン ド 亜 大 陸) #1(イ ス ラ ー ム) #1(定 着) #1(海 陸) #1(両 方) #1(経 路) #1(進 行) #1(カ イ バ ル 峠) #1(ル ー ト) #1(定 着) #1(過 程) #1(1 0 世 紀) #1(末) #1(1 6 世 紀) #1(前 半) #1(展 開) #1(政 治 的) #1(側 面) #1(文 化 的) #1(側 面) #1(双 方) #1(説 明) #1(政 治 的) #1(側 面) #1(文 化 的) #1(側 面) #1(双 方))',\n '#combine(イ ン ド 洋 地 域 で ， イ ギ リ ス や フ ラ ン ス の 東 イ ン ド 会 社 は ， イ ン ド 綿 布 を 中 心 に し た 貿 易 活 動 か ら 植 民 地 支 配 へ と 進 ん だ 。 1 8 世 紀 半 ば 頃 の イ ギ リ ス 東 イ ン ド 会 社 に よ る イ ン ド の 植 民 地 化 過 程 を ， フ ラ ン ス と の 関 係 に 留 意 し て で 説 明 し な さ い 。 フ ラ ン ス と の 関 係 に 留 意 し て #1(イ ン ド 洋) #1(地 域) #1(イ ギ リ ス) #1(フ ラ ン ス) #1(東 イ ン ド 会 社) #1(イ ン ド) #1(綿 布) #1(中 心) #1(貿 易) #1(活 動) #1(植 民 地 支 配) #1(1 8 世 紀) #1(半 ば) #1(頃) #1(イ ギ リ ス 東 イ ン ド 会 社) #1(イ ン ド) #1(植 民 地) #1(化) #1(過 程) #1(フ ラ ン ス) #1(関 係) #1(留 意) #1(説 明) #1(フ ラ ン ス) #1(関 係) #1(留 意))',\n '#combine(#1(ナ ポ レ オ ン) #1(ス エ ズ 運 河) #1(ナ セ ル))',\n '#combine(中 国 の 春 秋 時 代 に は ， 覇 者 と 呼 ば れ る 有 力 者 が 「 尊 王 攘 夷 」 を 唱 え て 盟 約 の 儀 式 を 主 宰 し た と い わ れ る 。 「 尊 王 攘 夷 」 と は 何 の こ と か 。 こ こ で い う 「 王 」 と は 何 か を 含 め て ， で 説 明 し な さ い 。 こ こ で い う 「 王 」 と は 何 か を 含 め て #1(中 国) #1(春 秋 時 代) #1(覇 者) #1(有 力) #1(者) #1(尊 王 攘 夷) #1(盟 約) #1(儀 式) #1(主 宰) #1(尊 王 攘 夷) #1(何) #1(こ と) #1(こ こ) #1(王) #1(何) #1(説 明) #1(こ こ) #1(王) #1(何))',\n '#combine(#1(グ ロ テ ィ ウ ス) #1(コ ー ヒ ー) #1(太 平 洋 戦 争) #1(長 崎) #1(ニ ュ ー ヨ ー ク) #1(ハ プ ス ブ ル ク 家) #1(マ ー ス ト リ ヒ ト 条 約) #1(南 ア フ リ カ 戦 争))',\n '#combine(そ れ ま で 複 数 の 有 力 な 思 想 の 一 つ に す ぎ な か っ た 儒 学 が ， 他 の 思 想 と は 異 な る 特 別 な 地 位 を 与 え ら れ た の は ， 前 漢 半 ば で あ っ た 。 そ の き っ か け と な っ た 出 来 事 に つ い て で 説 明 し な さ い 。 #1(そ れ) #1(複 数) #1(有 力) #1(思 想) #1(一 つ) #1(儒 学) #1(他) #1(思 想) #1(特 別) #1(地 位) #1(の) #1(前 漢) #1(半 ば) #1(き っ か け) #1(出 来 事) #1(説 明))',\n '#combine(唐 代 に 入 る と 詩 文 に は 様 々 な 変 化 が 起 こ っ た 。 文 章 に つ い て は 唐 代 中 期 以 降 ， 漢 代 以 前 に 戻 ろ う と す る 復 古 的 な 気 運 が 生 ま れ た 。 唐 代 に お け る そ の 気 運 に つ い て で 説 明 し な さ い 。 #1(唐 代) #1(詩 文) #1(様 々) #1(変 化) #1(文 章) #1(唐 代) #1(中 期) #1(以 降) #1(漢 代) #1(以 前) #1(復 古) #1(的) #1(気 運) #1(唐 代) #1(気 運) #1(説 明))',\n '#combine(1 5 世 紀 前 半 の 朝 鮮 で な さ れ た 特 徴 的 な 文 化 事 業 に つ い て で 説 明 し な さ い 。 #1(1 5 世 紀) #1(前 半) #1(朝 鮮) #1(特 徴) #1(的) #1(文 化) #1(事 業) #1(説 明))',\n '#combine(明 の 末 期 に な る と ， 中 国 の 知 識 人 た ち は ， イ エ ズ ス 会 宣 教 師 が も た ら し た ヨ ー ロ ッ パ の 科 学 技 術 に 強 い 関 心 を 示 し た 。 そ の 代 表 的 な 人 物 で あ る 徐 光 啓 の 活 動 に つ い て で 説 明 し な さ い 。 #1(明) #1(末 期) #1(中 国) #1(知 識 人) #1(た ち) #1(イ エ ズ ス 会) #1(宣 教 師) #1(ヨ ー ロ ッ パ) #1(科 学 技 術) #1(関 心) #1(代 表) #1(的) #1(人 物) #1(徐 光 啓) #1(活 動) #1(説 明))',\n '#combine(西 ア ジ ア の ア ラ ビ ア 半 島 で は ， ワ ッ ハ ー ブ 派 が 勢 力 を 拡 大 し た 。 こ の 運 動 に つ い て で 説 明 し な さ い 。 #1(西 ア ジ ア) #1(ア ラ ビ ア 半 島) #1(ワ ッ ハ ー ブ 派) #1(勢 力) #1(拡 大) #1(運 動) #1(説 明))',\n '#combine(中 国 で は ， 曾 国 藩 ・ 李 鴻 章 な ど の 官 僚 グ ル ー プ が 洋 務 運 動 と よ ば れ る 改 革 を 進 め た 。 こ の 運 動 の 性 格 に つ い て で 説 明 し な さ い 。 #1(中 国) #1(曾 国 藩) #1(李 鴻 章) #1(官 僚) #1(グ ル ー プ) #1(洋 務 運 動) #1(改 革) #1(運 動) #1(性 格) #1(説 明))',\n '#combine(#1(ア フ ガ ニ ス タ ン) #1(イ リ 地 方) #1(沿 海 州) #1(ク リ ミ ア 戦 争) #1(ト ル コ マ ン チ ャ ー イ 条 約) #1(ベ ル リ ン 会 議 （ 1 8 7 8 年 ）) #1(ポ ー ラ ン ド) #1(  旅 順))',\n '#combine(ビ ザ ン ツ 帝 国 （ 東 ロ ー マ 帝 国 ） は ， 6 世 紀 の ユ ス テ ィ ニ ア ヌ ス 帝 の 時 代 に 地 中 海 を と り ま く 多 く の 地 域 を 征 服 し 支 配 し た が ， 彼 の 死 後 ， 次 第 に そ の 支 配 地 を 失 っ て い っ た 。 そ の 過 程 で ， ビ ザ ン ツ 帝 国 の 歴 史 に 特 に 大 き な 影 響 を 与 え た の が ， ト ル コ 系 の 人 々 が 打 ち 立 て た 諸 国 家 に よ る 攻 撃 で あ っ た 。 こ の 経 緯 に つ い て で 記 述 し な さ い 。 #1(ビ ザ ン ツ 帝 国) #1(東 ロ ー マ 帝 国) #1(6 世 紀) #1(ユ ス テ ィ ニ ア ヌ ス 帝) #1(時 代) #1(地 中 海) #1(多 く) #1(地 域) #1(征 服) #1(支 配) #1(彼) #1(死 後) #1(支 配) #1(地) #1(過 程) #1(ビ ザ ン ツ 帝 国) #1(歴 史) #1(影 響) #1(の) #1(ト ル コ) #1(系) #1(人 々) #1(国 家) #1(攻 撃) #1(経 緯) #1(記 述))',\n '#combine(オ ラ ン ダ 東 イ ン ド 会 社 は ， 1 7 世 紀 か ら 1 8 世 紀 に か け て ， 次 第 に ジ ャ ワ 島 内 部 へ の 支 配 を 強 め た 。 こ の 当 時 ， ジ ャ ワ 島 内 で 発 展 し た 産 業 の 一 つ が 砂 糖 生 産 で あ り ， 砂 糖 生 産 に 関 わ る 技 術 や 一 部 の 労 働 力 は 中 国 か ら 導 入 さ れ た 。 こ の 背 景 に あ る 中 国 側 の 国 内 事 情 を で 記 述 し な さ い 。 #1(オ ラ ン ダ 東 イ ン ド 会 社) #1(1 7 世 紀) #1(1 8 世 紀) #1(ジ ャ ワ 島) #1(内 部) #1(支 配) #1(当 時) #1(ジ ャ ワ 島) #1(内) #1(発 展) #1(産 業) #1(一 つ) #1(砂 糖) #1(生 産) #1(砂 糖) #1(生 産) #1(技 術) #1(一 部) #1(労 働 力) #1(中 国) #1(導 入) #1(背 景) #1(中 国 側) #1(国 内) #1(事 情) #1(記 述))',\n '#combine(1 9 6 5 年 の は じ め ， ア メ リ カ 合 衆 国 は ベ ト ナ ム へ の 介 入 を さ ら に 強 化 す る 決 定 を 下 し た 。 こ の 決 定 を 下 し た 大 統 領 の 名 前 と そ の 内 容 を で 記 述 し な さ い 。 #1(1 9 6 5 年) #1(は じ め) #1(ア メ リ カ 合 衆 国) #1(ベ ト ナ ム) #1(介 入) #1(強 化) #1(決 定) #1(決 定) #1(大 統 領) #1(名 前) #1(内 容) #1(記 述))',\n '#combine(ベ ト ナ ム 戦 争 の 戦 費 の 拡 大 に よ り ， ア メ リ カ 合 衆 国 の 財 政 は 悪 化 し ， 1 9 7 1 年 に は そ の 経 済 政 策 の 変 更 を 余 儀 な く さ れ た 。 こ の 新 し い 政 策 の 内 容 と そ の 国 際 的 影 響 を で 記 述 し な さ い 。 #1(ベ ト ナ ム 戦 争) #1(戦 費) #1(拡 大) #1(ア メ リ カ 合 衆 国) #1(財 政) #1(悪 化) #1(1 9 7 1 年) #1(経 済 政 策) #1(変 更) #1(政 策) #1(内 容) #1(国 際 的) #1(影 響) #1(記 述))',\n '#combine(西 ヨ ー ロ ッ パ で は 中 世 都 市 が 発 展 す る と ， お も に 手 工 業 生 産 者 か ら な る ツ ン フ ト と よ ば れ る 組 織 が 形 成 さ れ ， 彼 ら が 主 体 と な る ツ ン フ ト 闘 争 が 各 地 で 起 こ っ た 。 こ の 闘 争 は 誰 に 対 す る 何 を 求 め た 闘 争 だ っ た か 。 で 記 述 し な さ い 。 #1(西 ヨ ー ロ ッ パ) #1(中 世 都 市) #1(発 展) #1(お も に) #1(手 工 業) #1(生 産) #1(者) #1(ツ ン フ ト) #1(組 織) #1(形 成) #1(彼 ら) #1(主 体) #1(ツ ン フ ト 闘 争) #1(各 地) #1(闘 争) #1(誰) #1(何) #1(闘 争) #1(記 述))',\n '#combine(エ ル ベ 川 以 東 の 東 ヨ ー ロ ッ パ 地 域 で は ， 近 世 に 入 る と 領 主 の 農 業 生 産 へ の 関 与 が 強 ま り ， グ ー ツ ヘ ル シ ャ フ ト と 呼 ば れ る 独 特 の 経 営 形 態 が 発 達 し た 。 こ の 農 業 経 営 の 特 色 を ， 当 時 の 交 易 の 発 展 と 関 連 づ け て で 記 述 し な さ い 。 当 時 の 交 易 の 発 展 と 関 連 づ け て #1(エ ル ベ 川) #1(以 東) #1(東) #1(ヨ ー ロ ッ パ 地 域) #1(近 世) #1(領 主) #1(農 業) #1(生 産) #1(関 与) #1(グ ー ツ ヘ ル シ ャ フ ト) #1(独 特) #1(経 営) #1(形 態) #1(発 達) #1(農 業 経 営) #1(特 色) #1(当 時) #1(交 易) #1(発 展) #1(記 述) #1(当 時) #1(交 易) #1(発 展))']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string_list_ja = get_query_string_list_ja(conditions_list_ja)\n",
    "query_string_list_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_ja = get_parameters_ja(query_string_list_ja)\n",
    "with open('qalab3-essay-phase2/indri/parameter_files/query-ja-phase2.xml', 'w') as f:\n",
    "    f.write(parameters_ja)\n",
    "result_ja = run_indri_query('qalab3-essay-phase2/indri/parameter_files/query-ja-phase2.xml')\n",
    "result_set_ja = parse_result(result_ja)\n",
    "result_set_with_docs_ja = attach_doc_ja(result_set_ja, 'qalab3-essay-phase2/ja_doc.db')\n",
    "result_set_with_sentences_ja = attach_sentence(result_set_with_docs_ja, query_string_list_ja)\n",
    "result_set_with_passages_ja = attach_passage(result_set_with_sentences_ja)\n",
    "extraction_xml_ja = get_extraction_xml(result_set_with_passages_ja, conditions_list_ja)\n",
    "with open('qalab3-essay-phase2/qalab3-ja-phase2-answersheet-essay_DGLab_extraction_01.xml', 'w') as f:\n",
    "    f.write(extraction_xml_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_en = et.parse('qalab3-essay-phase2/_references/qalab3-en-essay-phase2/qalab3-en-phase2-answersheet-essay.xml')\n",
    "conditions_list_en = get_conditions_list(tree_en.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#combine(#1(Battle of Actium) #1(Islam) #1(Ottoman Empire) #1(Saladin) #1(Nile River) #1(Nasser) #1(Napoleon) #1(Muhammed Ali))',\n '#combine(Japan participated in the federation in underlined section 1 but then left it Explain in  what led to leaving the federation federation #1(federation) #1(federation))',\n '#combine(One of the wars in underlined section 5 was the First Arab–Israeli War Palestine War which began in May 1948 Explain in  the outcome of this war series of battles #1(war) #1(series))',\n '#combine(#1(Abolition of the colonial slave system) #1(sugar cane plantation) #1(gold rush) #1(Haijin) #1(Opium Wars) #1(Straits Settlements) #1(rights recovery movement) #1(Sun Yatsen))',\n '#combine( changed its religious policy greatly during the 16th and 17th centuries Explain in  this change Include the names of the two popes involved Include the names of the two popes involved #1(change) #1(change))',\n '#combine( had a system for treating hereticsaWrite the name of this system andbexplain its features in  #1(andbexplain))',\n '#combine( and  had similar systems called the jagir and timar systems Describe in  which features these systems had in common #1(timar))',\n '#combine( shows a city with castle walls in the 16th century The construction of castle walls such as this with its protruding bastions flourished from the 16th century onwards What changed battle strategies and led to the construction of this type of castle wall Answer in  #1(Answer))',\n '#combine(#1(Treaty of Westphalia) #1(League of Nations) #1(Fourteen Points) #1(On the Law of War and Peace) #1(total war) #1(draft system) #1(nationalism) #1(Decree on Peace))',\n '#combine(Islam became entrenched in the Indian subcontinent over both land and sea routes In  explain the process of Islams establishment via the Khyber Pass route from the end of the 10th century to the first half of the 16th century discussing both political and cultural aspects discussing both political and cultural aspects #1(century) #1(century))',\n '#combine(In the Indian Ocean the British and French East India Companies advanced from engaging in trading activities focused on Indian cotton to controlling colonies In  explain the process of the colonization of India by the British East India Company in roughly the mid18th century noting its relationship to France as well noting its relationship to France as well #1(relationship) #1(relationship))',\n '#combine(#1(Napoleon) #1(Suez Canal) #1(Nasser))',\n '#combine(During Chinas Spring and Autumn era it is said that a powerful person known as the supreme ruler presided over a treaty ceremony calling for Zunwang Rangyi What does Zunwang Rangyi refer to Explain in 30 English words including what is meant by wang including what is meant by wang #1(wang) #1(wang))',\n '#combine(#1(Grotius) #1(coffee) #1(Pacific War) #1(Nagasaki) #1(New York) #1(Habsburgs) #1(Treaty of Maastricht) #1(South African War))',\n '#combine(During the middle of the Former Han era Confucianism which up until that point had been merely one of several valid schools of thought was given a special position of prominence separate from other schools of thought Explain in  what event led to this #1(event))',\n '#combine(Literary works underwent various changes in the Tang era Regarding writing from the middle of the Tang era onwards there was a revivalist drive towards a return to the Han era or earlier Explain in  this tendency in the Tang era #1(era))',\n '#combine(Describe in  representative cultural activities carried out in Joseon during the first half of the 15th century #1(century))',\n '#combine(In the end of the Ming era Chinese intellectuals showed a strong interest in the European scientific technologies introduced by Jesuit priests Describe in  the activities of Xu Guangqi a representative example of these intellectuals #1(example))',\n '#combine(In the Arabian Peninsula in western Asia the Wahhabists grew in power Describe in  this movement #1(movement))',\n '#combine(In China a group of bureaucrats including Zeng Guofan and Li Hongzhang implemented reforms known as the Westernization movement Describe in  the character of this movement #1(movement))',\n '#combine(#1(Afghanistan) #1(Ili region) #1(Primorye) #1(Crimean War) #1(Treaty of Turkmenchay) #1(Berlin Conference 1878) #1(Poland) #1(Port Arthur))',\n '#combine(The Byzantine Empire Eastern Roman Empire conquered many regions around the Mediterranean Sea during the 6th century reign of Emperor Justinian but following his death it gradually lost control of these lands During this process attacks by countries established by Turkish peoples had a tremendous impact on the history of the Byzantine Empire Give an account of this in four lines or less #1(account))',\n '#combine(From the 17th century to the 18th century the Dutch East India Company gradually strengthened its control over the interior of the island of Java One of the developed industries in Java at the time was the sugar production industry Sugar production technologies and some labor was introduced from China Explain in  the internal conditions in China which led to this #1(labor))',\n '#combine(At the start of 1965 the United States of America decided to further intervene in Vietnam In  write the name of the president that made this decision and the contents of the decision #1(decision))',\n '#combine(As the cost of the Vietnam War rose the finances of the United States of America deteriorated and in 1971 the country was forced to change its economic policy In  describe the content of the new economic policy and its international impact #1(impact))',\n '#combine(In Western Europe the development of medieval cities led to the formation of organizations called Zunft consisting primarily of handicraftsmen The Zunft which they led engaged in battles in various regions In  explain who these battles were against and what they demanded #1(Zunft))',\n '#combine(In Eastern Europe to the east of the Elbe River from the start of the early modern period feudal lords became more involved with agricultural production and a unique management form called Gutsherrschaft developed Describe the characteristics of this agricultural management in relationship to development of trade at the time Answer in  in relationship to development of trade at the time #1(Answer) #1(time))']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string_list_en = get_query_string_list_en(conditions_list_en)\n",
    "query_string_list_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_en = get_parameters_en(query_string_list_en)\n",
    "with open('qalab3-essay-phase2/indri/parameter_files/query-en-phase2.xml', 'w') as f:\n",
    "    f.write(parameters_en)\n",
    "result_en = run_indri_query('qalab3-essay-phase2/indri/parameter_files/query-en-phase2.xml')\n",
    "result_set_en = parse_result(result_en)\n",
    "result_set_with_docs_en = attach_doc_en(result_set_en, 'qalab3-essay-phase2/en_doc.db')\n",
    "result_set_with_sentences_en = attach_sentence(result_set_with_docs_en, query_string_list_en)\n",
    "result_set_with_passages_en = attach_passage(result_set_with_sentences_en)\n",
    "extraction_xml_en = get_extraction_xml(result_set_with_passages_en, conditions_list_en)\n",
    "with open('qalab3-essay-phase2/qalab3-en-phase2-answersheet-essay_DGLab_extraction_01.xml', 'w') as f:\n",
    "    f.write(extraction_xml_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}