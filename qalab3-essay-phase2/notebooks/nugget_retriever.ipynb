{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import mkdir, path\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "\n",
    "mecab_ipadic_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd/'\n",
    "assert path.exists(mecab_ipadic_path), 'mecab-ipadic-neologd not found. Exitting.'\n",
    "mecab = MeCab.Tagger('-Owakati -d {}'.format(mecab_ipadic_path))\n",
    "mecab.parse('')\n",
    "\n",
    "\n",
    "def tokenize_ja_word(text):\n",
    "    return mecab.parse(text).strip()\n",
    "\n",
    "\n",
    "def tokenize_ja(text):\n",
    "    return ' '.join(list(text.strip()))\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    with Popen(['java', 'edu.stanford.nlp.process.PTBTokenizer', '-preserveLines'],\n",
    "               stdin=PIPE, stdout=PIPE, stderr=PIPE) as tokenizer_proc:\n",
    "        out, err = tokenizer_proc.communicate(input=text.encode('UTF-8'))\n",
    "        return out.decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters_ja(query_string_list_ja, index_name='passages_ja'):\n",
    "    parameter_template = (\n",
    "        '<parameters>\\n'\n",
    "        ' <index>../../qalab3-essay-phase2/indri/indexes/{}</index>\\n'\n",
    "        '\\n{}\\n'\n",
    "        '</parameters>\\n'\n",
    "    )\n",
    "    query_element_template = (\n",
    "        '  <query>\\n'\n",
    "        '   <type>indri</type>\\n'\n",
    "        '   <number>{}</number>\\n'\n",
    "        '   <text>\\n'\n",
    "        '    {}\\n'\n",
    "        '   </text>\\n'\n",
    "        '  </query>\\n'\n",
    "    )\n",
    "\n",
    "    query_elements = []\n",
    "    for i, query in enumerate(query_string_list_ja):\n",
    "        query_element = query_element_template.format(i, query)\n",
    "        query_elements.append(query_element)\n",
    "    parameters = parameter_template.format(index_name, '\\n'.join(query_elements))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_parameters_en(query_string_list_en, index_name='passages_en'):\n",
    "    parameter_template = (\n",
    "        '<parameters>\\n'\n",
    "        ' <index>../../qalab3-essay-phase2/indri/indexes/{}</index>\\n'\n",
    "        ' <stemmer><name>krovetz</name></stemmer>\\n'\n",
    "        '\\n{}\\n'\n",
    "        '</parameters>\\n'\n",
    "    )\n",
    "    query_element_template = (\n",
    "        '  <query>\\n'\n",
    "        '   <type>indri</type>\\n'\n",
    "        '   <number>{}</number>\\n'\n",
    "        '   <text>\\n'\n",
    "        '    {}\\n'\n",
    "        '   </text>\\n'\n",
    "        '  </query>\\n'\n",
    "    )\n",
    "\n",
    "    query_elements = []\n",
    "    for i, query in enumerate(query_string_list_en):\n",
    "        query_element = query_element_template.format(i, query)\n",
    "        query_elements.append(query_element)\n",
    "    parameters = parameter_template.format(index_name, '\\n'.join(query_elements))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_indri_query(parameter_file_path):\n",
    "    with Popen(['IndriRunQuery', parameter_file_path, '-trecFormat=true', '-count=37'],\n",
    "               stdout=PIPE, stderr=PIPE) as indri_proc:\n",
    "        out, err = indri_proc.communicate()\n",
    "        return out.decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_result(result):\n",
    "    result_set = {}\n",
    "    result_lines = result.splitlines()\n",
    "    for line in result_lines:\n",
    "        fields = line.split(' ')\n",
    "        serial = fields[0]\n",
    "        doc_id = fields[2]\n",
    "        score = fields[4]\n",
    "        if serial not in result_set:\n",
    "            result_set[serial] = []\n",
    "        result_set[serial].append({'doc_id': doc_id, 'score': score})\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_string_en(prop_text):\n",
    "    def pattern_filter(text):\n",
    "        patterns = [\n",
    "            r'(\\d+ English words or less)',\n",
    "            r'[\\(\\)]',\n",
    "            r'(underlined section \\(\\d+\\))',\n",
    "            r'(Plate \\w)',\n",
    "            r'\\b[XYZ]\\b',\n",
    "            r'[,.?\\'\"\\-`“”’]',\n",
    "            r'(’s)'\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "\n",
    "        return text\n",
    "    return '#combine({})'.format(tokenize_en(pattern_filter(prop_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_string_ja(prop_text):\n",
    "    def pattern_filter(text):\n",
    "        patterns = [r'\\d+字以内', r'[\\(\\)。、]', r'下線部\\w', r'図版\\w', r'[ＸＹＺ]']\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "        return text\n",
    "\n",
    "    keyterms = tokenize_ja_word(pattern_filter(prop_text)).split(' ')\n",
    "    phrases = []\n",
    "    for keyterm in keyterms:\n",
    "        phrases.append('#1({})'.format(' '.join(list(keyterm))))\n",
    "    return '#combine({})'.format(' '.join(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prop_id_text_pairs(root, exam_id):\n",
    "    prop_id_text_pairs = []\n",
    "    exam = root.find('exam/[@id=\"{}\"]'.format(exam_id))\n",
    "    for ans in exam.iter('answer'):\n",
    "        annotator_id = ans.get('annotator')\n",
    "        for sem in ans.iter('semantic_unit'):\n",
    "            sem_id = sem.get('id')\n",
    "            for prop in sem.iter('proposition'):\n",
    "                prop_id = '{}_{}_{}'.format(annotator_id, sem_id, prop.get('id'))\n",
    "                prop_text = prop.get('value')\n",
    "                prop_id_text_pairs.append((prop_id, prop_text))\n",
    "    return prop_id_text_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_folder_path_en = '../../qalab3-essay-phase2/_references/qalab3-en-essay-phase2/qalab3-en-phase2-nugget-essay'\n",
    "\n",
    "nugget_file_names_en = ['B792W10.xml', 'C792W10.xml']\n",
    "exam_id_list_en = ['B792W10_[1]', 'C792W10_[1]']\n",
    "conditions_en = {}\n",
    "for file, exam_id in zip(nugget_file_names_en, exam_id_list_en):\n",
    "    tree_en = et.parse('{}/{}'.format(ref_folder_path_en, file))\n",
    "    root_en = tree_en.getroot()\n",
    "    prop_list = get_prop_id_text_pairs(root_en, exam_id)\n",
    "    conditions_en[exam_id] = prop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for exam_en, condition_en in conditions_en.items():\n",
    "    query_string_list_en = [get_query_string_en(prop_text) for prop_id, prop_text in condition_en]\n",
    "\n",
    "    param_en = get_parameters_en(query_string_list_en)\n",
    "    param_file_en = '../../qalab3-essay-phase2/indri/parameter_files/query-nugget_en_{}.xml'.format(exam_en)\n",
    "    with open(param_file_en, 'w') as f:\n",
    "        f.write(param_en)\n",
    "    result = run_indri_query(param_file_en)\n",
    "    result_set = parse_result(result)\n",
    "    with open('../../qalab3-essay-phase2/workspace/candidates_en_{}.txt'.format(exam_en), 'w') as f:\n",
    "        for i, prop in enumerate(condition_en):\n",
    "            passage_list = result_set[str(i)]\n",
    "            prop_id = prop[0]\n",
    "            for passage in passage_list:\n",
    "                if passage['doc_id'][0] == exam_en[0]:\n",
    "                    f.write('{}\\t{:.5f}\\t{}\\n'.format(prop_id, float(passage['score']), passage['doc_id']))\n",
    "            f.write('\\n')\n",
    "\n",
    "    essay_param_en = get_parameters_en(query_string_list_en, 'essays_en')\n",
    "    essay_param_file_en = '../../qalab3-essay-phase2/indri/parameter_files/query-essay-nugget_en_{}.xml'.format(\n",
    "        exam_en)\n",
    "    with open(essay_param_file_en, 'w') as f:\n",
    "        f.write(essay_param_en)\n",
    "    result = run_indri_query(essay_param_file_en)\n",
    "    result_set = parse_result(result)\n",
    "    with open('../../qalab3-essay-phase2/workspace/candidates_essay_nugget_en_{}.txt'.format(exam_en), 'w') as f:\n",
    "        for i, prop in enumerate(condition_en):\n",
    "            ans_list = result_set[str(i)]\n",
    "            prop_id = prop[0]\n",
    "            for ans in ans_list:\n",
    "                if ans['doc_id'][0] == exam_en[0]:\n",
    "                    f.write('{}\\t{:.5f}\\t{}\\n'.format(prop_id, float(ans['score']), ans['doc_id']))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_folder_path_ja = '../../qalab3-essay-phase2/_references/qalab3-ja-essay-phase2/qalab3-ja-phase2-nugget-essay'\n",
    "\n",
    "nugget_file_names_ja = ['B792W10.xml', 'C792W10.xml']\n",
    "exam_id_list_ja = ['B792W10_【１】', 'C792W10_【１】']\n",
    "conditions_ja = {}\n",
    "for file, exam_id in zip(nugget_file_names_ja, exam_id_list_ja):\n",
    "    tree_ja = et.parse('{}/{}'.format(ref_folder_path_ja, file))\n",
    "    root_ja = tree_ja.getroot()\n",
    "    prop_list = get_prop_id_text_pairs(root_ja, exam_id)\n",
    "    conditions_ja[exam_id] = prop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for exam_ja, condition_ja in conditions_ja.items():\n",
    "    query_string_list_ja = [get_query_string_ja(prop_text) for prop_id, prop_text in condition_ja]\n",
    "\n",
    "    param_ja = get_parameters_ja(query_string_list_ja)\n",
    "    param_file_ja = '../../qalab3-essay-phase2/indri/parameter_files/query-nugget_ja_{}.xml'.format(exam_ja)\n",
    "    with open(param_file_ja, 'w') as f:\n",
    "        f.write(param_ja)\n",
    "    result = run_indri_query(param_file_ja)\n",
    "    result_set = parse_result(result)\n",
    "    with open('../../qalab3-essay-phase2/candidates_ja_{}.txt'.format(exam_ja), 'w') as f:\n",
    "        for i, prop in enumerate(condition_ja):\n",
    "            passage_list = result_set[str(i)]\n",
    "            prop_id = prop[0]\n",
    "            for passage in passage_list:\n",
    "                if passage['doc_id'][0] == exam_ja[0]:\n",
    "                    f.write('{}\\t{:.5f}\\t{}\\n'.format(prop_id, float(passage['score']), passage['doc_id']))\n",
    "\n",
    "    essay_param_ja = get_parameters_en(query_string_list_ja, 'essays_ja')\n",
    "    essay_param_file_ja = '../../qalab3-essay-phase2/indri/parameter_files/query-essay-nugget_ja_{}.xml'.format(\n",
    "        exam_ja)\n",
    "    with open(essay_param_file_ja, 'w') as f:\n",
    "        f.write(essay_param_ja)\n",
    "    result = run_indri_query(essay_param_file_ja)\n",
    "    result_set = parse_result(result)\n",
    "    with open('../../qalab3-essay-phase2/workspace/candidates_essay_nugget_ja_{}.txt'.format(exam_ja), 'w') as f:\n",
    "        for i, prop in enumerate(condition_ja):\n",
    "            ans_list = result_set[str(i)]\n",
    "            prop_id = prop[0]\n",
    "            for ans in ans_list:\n",
    "                if ans['doc_id'][0] == exam_ja[0]:\n",
    "                    f.write('{}\\t{:.5f}\\t{}\\n'.format(prop_id, float(ans['score']), ans['doc_id']))\n",
    "            f.write('\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
